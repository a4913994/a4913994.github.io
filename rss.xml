<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title></title>
        <link>undefined</link>
        <description>undefined</description>
        <lastBuildDate>Wed, 19 Apr 2023 13:57:49 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>Joplin Pages Publisher</generator>
        <item>
            <title><![CDATA[OOM]]></title>
            <guid>f37eae6d84674ed88bac2e2b754b9934</guid>
            <pubDate>Wed, 19 Apr 2023 13:56:43 GMT</pubDate>
            <content:encoded><![CDATA[<h3 id="学习资料">学习资料</h3>
<p>要学习 Linux OOM（Out-of-Memory）相关的内容，你需要查看以下源代码文件：</p>
<ul>
<li>mm/oom_kill.c: 这个文件包含了 OOM killer 的主要实现代码，包括选择要杀死的进程、计算进程的 OOM 分数等功能。</li>
<li>include/linux/oom.h: 这个文件包含了 OOM 相关的数据结构定义，例如 struct oom_control，以及 OOM 相关的一些宏定义。</li>
<li>mm/page_alloc.c: 这个文件包含了内存分配的代码，包括内存分配失败时触发 OOM 的逻辑。</li>
<li>mm/vmscan.c: 这个文件包含了内核中的内存回收机制，其中也涉及了在内存压力过大时触发 OOM 的部分逻辑。</li>
<li>include/linux/memcontrol.h 和 mm/memcontrol.c: 这两个文件包含了内存 cgroup（控制组）的实现。OOM killer 也可以在 cgroup 内触发，以便在特定的 cgroup 内释放内存。</li>
<li>kernel/sysctl.c: 这个文件包含了内核参数（sysctl）的实现，其中包括 OOM 相关的参数，例如调整 OOM killer 的启用或禁用。</li>
<li>fs/proc/base.c 和 fs/proc/task_mmu.c: 这两个文件包含了 /proc 文件系统中与 OOM 相关的信息的实现，例如 /proc/<pid class="jop-noMdConv">/oom_score 和 /proc/<pid class="jop-noMdConv">/oom_score_adj。<br />
学习这些文件将帮助你了解 Linux OOM 的实现原理、触发条件、处理过程以及如何调整 OOM 行为。由于 Linux 内核代码较为复杂，建议先阅读概念性的文章和文档以了解 OOM 的基本概念和原理，然后再深入阅读源代码。</pid></pid></li>
</ul>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[共享内存]]></title>
            <guid>3dcbaa4cae934e679ad1d58e28b6642e</guid>
            <pubDate>Wed, 19 Apr 2023 13:56:10 GMT</pubDate>
            <content:encoded><![CDATA[<h3 id="资料">资料</h3>
<p>要学习 Linux 共享内存（Shared Memory）相关的内容，可以查看以下源代码文件：</p>
<ul>
<li>ipc/shm.c: 这个文件包含了 System V 共享内存实现的主要代码。System V 共享内存是 Linux 中最早的共享内存实现。</li>
<li>ipc/util.c: 这个文件包含了 IPC（包括共享内存）相关的辅助功能和数据结构。</li>
<li>include/linux/shm.h: 这个文件包含了 System V 共享内存的一些常量、宏和结构体定义。</li>
<li>mm/mmap.c: 这个文件包含了内存映射（mmap）的实现代码。内存映射可以用于创建共享内存区域，例如使用 MAP_SHARED 标志。mmap 也是实现 POSIX 共享内存的基础。</li>
<li>include/linux/mman.h: 这个文件包含了内存映射相关的宏、常量和结构体定义。</li>
<li>fs/proc/task_mmu.c: 这个文件包含了 /proc 文件系统中与共享内存相关的信息的实现，例如 /proc/<pid class="jop-noMdConv">/maps。</pid></li>
<li>fs/hugetlbfs/inode.c: 这个文件包含了 hugetlbfs 的实现，hugetlbfs 可以用于创建大页（huge pages）的共享内存区域。<br />
学习这些文件将帮助你了解 Linux 共享内存的实现原理、操作方式和与其他系统组件的交互。此外，建议先阅读关于共享内存的概念性文章和文档，以便了解基本概念和原理，然后再深入阅读源代码。</li>
</ul>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[内存管理]]></title>
            <guid>326f6a784a8341049d9e6bb44a734024</guid>
            <pubDate>Wed, 12 Apr 2023 14:01:25 GMT</pubDate>
            <content:encoded><![CDATA[<h2 id="从oomout-of-memory开始">从OOM(Out Of Memory)开始</h2>
<blockquote>
<p>内存溢出（OOM，Out Of Memory）错误是指当内核在其内部内存池中耗尽内存且无法从其他来源回收内存时发生的情况。它基本上会开始随机终止进程，并在dmesg中生成大量日志。</p>
</blockquote>
<h3 id="导致内存溢出oom的原因是什么">导致内存溢出（OOM）的原因是什么？</h3>
<p>通常，系统在回收内存方面表现得相当懒散，更倾向于让内存留在缓存中，直到真正需要使用。因此，如果没有内存请求，看到内存使用量增长而不减少并不罕见。当有内存请求时，系统可能会选择释放一些无人使用的内存以满足请求，或者将仍在使用的数据放到交换空间中，然后交出现在可用的内存。如果交换空间上的数据再次被需要，它将替换一些其他不再使用的内存。当这种替换过程被认为已经停止取得进展时，就会发生内存溢出（OOM）。</p>
<p>当内存紧张时，整个进程会被终止，理论上这样做可以释放大量内存。这并不是一个完全理想的解决方案，但它确实（理论上）允许系统继续运行。然而在实践中，用户通常会反感他们的进程被强制终止，这通常也是问题引起关注的时候。</p>
<h3 id="导致这些内存溢出oom事件的原因是什么">导致这些内存溢出（OOM）事件的原因是什么？</h3>
<ul>
<li>内核确实内存不足, 工作负载使用的内存超过了系统的RAM和交换空间
<ul>
<li>在<code>/proc/meminfo</code>中，查看<code>SwapFree</code>和<code>MemFree</code>分别是什么？如果两者都非常低（小于总量的1%），那么工作负载可能有问题。（除非涉及到<code>mlock()</code>或<code>HugeTLB</code>，具体请见下文...)
<ul>
<li>SwapFree：表示系统中当前可用的交换空间大小，单位是KB</li>
<li>MemFree：表示系统中当前可用的物理内存大小，单位是KB</li>
</ul>
</li>
</ul>
</li>
<li>在32位架构上，内核的低内存耗尽了
<ul>
<li>在<code>/proc/meminfo</code>中，<code>LowFree</code>是什么？如果它非常低，但<code>HighFree</code>要高得多，那么你可能面临这种情况。这种工作负载在64位平台或内核上运行可能会有益处。</li>
</ul>
</li>
<li>存在内核数据结构或内存泄漏问题
<ul>
<li>在<code>/proc/meminfo</code>文件中，查看<code>SwapFree</code>和<code>MemFree</code>分别是什么？</li>
<li>在<code>slabinfo</code>中，<code>task_struct</code>对象的数量是多少？系统是否创建了如此多的进程，以至于耗尽了内存？
<ul>
<li>这里需要你查看<code>/proc/slabinfo</code>文件，找到<code>task_struct</code>对应的行，其中会显示当前系统中<code>task_struct</code>对象的数量。如果数量过多，可能是系统创建了过多进程，导致内存耗尽</li>
</ul>
</li>
<li>在/proc/slabinfo中，哪些对象占用了最多的空间？如果某种对象占据了系统总内存的绝大部分，那么这个对象可能是问题所在。要查看对象的使用情况，请在命令行上运行以下命令：
<ul>
<li><code>awk '{printf "%5d MB %s\n", $3*$4/(1024*1024), $1}' &lt; /proc/slabinfo | sort -n</code></li>
</ul>
</li>
<li>内核没有正确使用其交换空间
<ul>
<li>如果应用程序使用<code>mlock()</code>或<code>HugeTLBfs</code>页，则可能无法为该应用程序使用其交换空间。如果发生这种情况，当OOM发生时，<code>SwapFree</code>可能仍然有一个非常大的值。但是，这两个特性不允许系统交换受影响的内存，因此过度使用它们可能耗尽系统内存，使系统没有其他资源</li>
<li>系统也可能陷入一种类似死锁的状态。将数据写入磁盘本身可能需要为各种I/O数据结构分配内存。如果系统连这些内存都找不到，用于创建空闲内存的函数将受到限制，系统很可能会耗尽内存。可以通过进行一些微调来更早地开始分页，但是如果系统无法足够快地将脏页写出以释放内存，那么我们只能得出结论：工作负载与已安装的内存不匹配，而且没有太多可做的事情。提高<code>/proc/sys/vm/min_free_kbytes</code>中的值会使系统比以前更早地开始回收内存。这使得陷入这种死锁的难度更大。</li>
</ul>
</li>
<li>内核做出了错误的决策，并误读了其统计数据, 在还有大量可用的优质RAM的情况下，系统发生了内存溢出（OOM）</li>
<li>发生了一些非常病态的情况。实际上，在花费了“相当多”的时间扫描内存寻找可释放内容后，内核决定触发内存溢出（OOM),  如果内核正在快速扫描页面，但是您的I/O设备(交换、文件系统或网络fs)太慢，内核可能会判断没有任何进展，即使有交换空闲，也会触发OOM</li>
</ul>
</li>
</ul>
<h2 id="走进linux的内存演化路线">走进Linux的内存演化路线</h2>
<h3 id="发展历程">发展历程</h3>
<ol>
<li>
<p><strong>早期阶段(1991年-2001年):</strong>  在早期的Linux内核版本中，内存管理主要依赖于x86硬件架构的页表机制。在这个阶段，内存管理主要包括内存分配和回收、虚拟内存、页面置换等基本功能。早期的Linux内核使用了经典的Buddy System算法来管理物理内存，该算法可以高效地分配和回收大块物理内存。</p>
</li>
<li>
<p><strong>2.4内核阶段(2001年-2003年):</strong>  随着计算机技术的不断发展，内存容量也越来越大，早期的内存管理方案已经无法满足需求。因此，Linux内核开始引入一系列新的内存管理机制，例如Slab Allocator、NUMA和高速缓存等，以支持更大规模的内存管理。在2.4版本的内核中，Linux内存管理的设计和实现更加高效和灵活。</p>
</li>
<li>
<p><strong>2.6内核阶段(2003年-2011年):</strong>  2.6版本的内核是Linux内存管理的一个重要里程碑，它引入了许多新的特性，例如：内存压缩、大页面、回收和管理虚拟内存、Memory Controller等。此外，2.6内核还加入了可扩展的物理页框架（SPF）和完整性保护（Integrity Protection）等高级特性。</p>
</li>
<li>
<p><strong>3.x和4.x内核阶段(2011年-至今):</strong>  自3.x和4.x内核以来，Linux内存管理的重点已经转移到了能耗优化、虚拟化和NUMA等方面。新的特性包括Transparent Huge Pages、Control Group（Cgroup）等，可以帮助管理员更好地管理系统内存。同时，内核还引入了对无线电源管理、休眠模式和睡眠状态等特性的支持，以更好地满足现代计算机的需求。</p>
</li>
</ol>
<h3 id="linux各版本中涉及的重要特性和改进">Linux各版本中涉及的重要特性和改进</h3>
<ol>
<li>
<p>Linux 0.0.1 (1991年)：最初的Linux版本只支持1MB的物理内存，使用简单的伙伴系统（Buddy System）来管理物理内存。</p>
</li>
<li>
<p>Linux 1.0 (1994年)：支持2GB的物理内存，引入了虚拟内存和页面置换功能。</p>
</li>
<li>
<p>Linux 2.2 (1999年)：引入了高速缓存、共享内存和NUMA支持等特性，以支持更大规模的内存管理。</p>
</li>
<li>
<p>Linux 2.4 (2001年)：引入了Slab Allocator来管理内核对象的内存分配和回收，可以高效地处理小块内存。此外，2.4版本还支持大页面（Huge Pages）和内存压缩（Memory Compression）等特性。</p>
</li>
<li>
<p>Linux 2.6 (2003年)：引入了Memory Controller和Completely Fair Scheduler（CFS）等特性，可以更好地管理和调度系统内存和进程。此外，2.6版本还支持SPF和完整性保护（Integrity Protection）等高级特性。</p>
</li>
<li>
<p>Linux 3.x和4.x (2011年-至今)：引入了Transparent Huge Pages、Control Group（Cgroup）等特性，可以帮助管理员更好地管理系统内存。同时，内核还引入了对无线电源管理、休眠模式和睡眠状态等特性的支持。</p>
</li>
</ol>
<h3 id="源码分析">源码分析</h3>
<h4 id="linux-001">Linux 0.0.1</h4>
<p><a title="https://github.com/zavg/linux-0.01.git" href="https://github.com/zavg/linux-0.01.git">Linux 0.0.1</a></p>
<p>内存管理相关的文件：</p>
<ol>
<li><code>include/asm/memory.h</code>: 定义了<code>memcpy</code>函数</li>
<li><code>mm/memory.c</code>: 主要实现了<code>include/linux/mm.h</code>中<code>get_free_page</code>, <code>put_page</code>和<code>free_page</code>三个内存分配函数</li>
<li>在这一版的源码中已经出现了<code>HIGH_MEMORY</code>，<code>LOW_MEMORY</code>和<code>vmem_map</code>等概念</li>
</ol>
<h3 id="linux-10">Linux 1.0</h3>
<h3 id="linux-4x">LInux 4.x</h3>
<div><pre class="hljs"><code>+--------------------------------------+
|         用户态 (User space)           |
+--------------------------------------+
|         内核态 (Kernel space)         |
+---------+----------+-----------------+
| 物理内存 | 页表管理 | 高速缓存 &amp; 缓冲区  |
+---------+----------+-----------------+
|           硬件层 (Hardware)           |
+--------------------------------------+</code></pre></div>
<ul>
<li>用户态 (User space)：用户程序和应用程序运行的区域。</li>
<li>内核态 (Kernel space)：内核代码和数据结构所在的区域。</li>
<li>物理内存 (Physical memory)：用于存储内核、用户程序和数据的实际内存。</li>
<li>页表管理 (Page table management)：用于管理虚拟地址到物理地址的映射关系。</li>
<li>高速缓存 &amp; 缓冲区 (Cache &amp; Buffer)：用于加速内存访问和数据交换的缓存结构。</li>
<li>硬件层 (Hardware)：包括物理内存、CPU 和其他硬件设备。</li>
</ul>
<h4 id="虚拟内存">虚拟内存</h4>
<div><pre class="hljs"><code>+-----------------------------+
|      虚拟地址空间 (VAS)        |
+-------------+---------------+
|  用户虚拟地址 | 内核虚拟地址    |
+------+------+------+--------+
| 页全局目录 | 页上级目录 | 页目录 | 页表 |
+------+------+------+--------+
|       物理地址空间 (PAS)        |
+-----------------------------+</code></pre></div>
<ul>
<li>虚拟地址空间 (Virtual Address Space, VAS)：操作系统为每个进程分配的地址空间。</li>
<li>用户虚拟地址 (User virtual address)：用户程序和应用程序运行的虚拟地址区域。</li>
<li>内核虚拟地址 (Kernel virtual address)：内核代码和数据结构的虚拟地址区域。</li>
<li>页全局目录 (Page Global Directory)：最高级别的页表，用于指向页上级目录。</li>
<li>页上级目录 (Page Upper Directory)：用于指向页目录。</li>
<li>页目录 (Page Directory)：用于指向页表。</li>
<li>页表 (Page Table)：用于将虚拟地址映射到物理地址。</li>
<li>物理地址空间 (Physical Address Space, PAS)：实际内存的地址空间。</li>
</ul>
<div><pre class="hljs"><code>+------------------------------------+
|       虚拟地址空间 (VAS)              |
|+----------------------------------+|
||      用户虚拟地址 (UVA)            ||
||+------------+------------+------+||
||| 用户栈     | 用户数据    | 用户代码 |||
||+------------+------------+------+||
|+----------------------------------+|
|+----------------------------------+|
||      内核虚拟地址 (KVA)            ||
||+------------+------------+------+||
||| 内核栈     | 内核数据    | 内核代码 |||
||+------------+------------+------+||
|+----------------------------------+|
+------------------------------------+
</code></pre></div>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[限流算法]]></title>
            <guid>e877991b34564e5788dda7604a0d76af</guid>
            <pubDate>Wed, 12 Apr 2023 12:38:42 GMT</pubDate>
            <content:encoded><![CDATA[<blockquote>
<p>节流算法是用于控制应用程序或系统消耗资源或处理请求的速率的技术，有助于维护系统的稳定性，保证资源的公平分配，防止系统过载或崩溃。</p>
</blockquote>
<h3 id="常见的节流算法">常见的节流算法</h3>
<ol>
<li>令牌桶算法:该算法维护一个虚拟的令牌桶，在处理请求时使用这些令牌。令牌以固定的速率生成，如果没有令牌，请求要么被丢弃，要么被延迟，直到新的令牌可用为止。这种方法允许高请求率的短爆发，使总请求率随着时间的推移变得平稳。</li>
<li>漏桶算法:漏桶算法与令牌桶算法类似，也使用了虚拟桶。但是，它不使用令牌，而是累积传入的请求，并以恒定的速率处理它们。如果桶已满，新的传入请求将被丢弃或延迟。该算法执行严格的、一致的请求率。</li>
<li>固定窗口速率限制:该算法将时间划分为固定的窗口(例如，每秒、分钟或小时)，并允许每个窗口内的最大请求数量。如果达到限制，新的请求要么被丢弃，要么被延迟，直到下一个窗口开始。这种方法实现起来很简单，但可能会导致在新窗口开始时出现请求爆发。</li>
<li>滑动窗口速率限制:该算法改进了固定的窗口速率限制，允许在一个滑动窗口时间内(例如，在任何60秒间隔内)的最大请求数量。它减轻了固定窗口速率限制中出现的突发问题，并提供了对请求速率的更流畅的控制。</li>
<li>自适应速率限制:该算法根据当前系统负载、延迟或其他因素动态调整允许的请求速率。它的实现可能更加复杂，但通过实时适应不断变化的条件提供更好的资源管理。</li>
<li>指数回退:这是在重试机制中使用的策略，客户端逐渐增加重试之间的等待时间，以减少系统上的请求负载。每次请求失败后，客户端等待的时间呈指数增长，然后再发送另一个请求。这种方法在处理速率限制或瞬态错误时特别有用。</li>
</ol>
<h3 id="滑动窗口速率限制算法实现">滑动窗口速率限制算法实现</h3>
<div><pre class="hljs"><code><span class="hljs-keyword">package</span> main

<span class="hljs-keyword">import</span> (
    <span class="hljs-string">"fmt"</span>
    <span class="hljs-string">"sync"</span>
    <span class="hljs-string">"time"</span>
)

<span class="hljs-keyword">type</span> RateLimiter <span class="hljs-keyword">struct</span> {
    sync.Mutex
    maxRequests  <span class="hljs-keyword">int</span>
    windowLength time.Duration
    requests     <span class="hljs-keyword">map</span>[<span class="hljs-keyword">int64</span>]<span class="hljs-keyword">int</span>
}

<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">NewRateLimiter</span><span class="hljs-params">(maxRequests <span class="hljs-keyword">int</span>, windowLength time.Duration)</span> *<span class="hljs-title">RateLimiter</span></span> {
    <span class="hljs-keyword">return</span> &amp;RateLimiter{
        maxRequests:  maxRequests,
        windowLength: windowLength,
        requests:     <span class="hljs-built_in">make</span>(<span class="hljs-keyword">map</span>[<span class="hljs-keyword">int64</span>]<span class="hljs-keyword">int</span>),
    }
}

<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(r *RateLimiter)</span> <span class="hljs-title">Allow</span><span class="hljs-params">()</span> <span class="hljs-title">bool</span></span> {
    r.Lock()
    <span class="hljs-keyword">defer</span> r.Unlock()

    now := time.Now().Unix()
    earliest := now - <span class="hljs-keyword">int64</span>(r.windowLength.Seconds())

    <span class="hljs-comment">// Clean up expired timestamps</span>
    <span class="hljs-keyword">for</span> timestamp := <span class="hljs-keyword">range</span> r.requests {
        <span class="hljs-keyword">if</span> timestamp &lt; earliest {
            <span class="hljs-built_in">delete</span>(r.requests, timestamp)
        }
    }

    <span class="hljs-comment">// Count requests in the current sliding window</span>
    requestCount := <span class="hljs-number">0</span>
    <span class="hljs-keyword">for</span> _, count := <span class="hljs-keyword">range</span> r.requests {
        requestCount += count
    }

    <span class="hljs-comment">// Check if the request can be allowed</span>
    <span class="hljs-keyword">if</span> requestCount &lt; r.maxRequests {
        r.requests[now]++
        <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>
    }

    <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>
}

<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> {
    limiter := NewRateLimiter(<span class="hljs-number">5</span>, <span class="hljs-number">10</span>*time.Second)

    <span class="hljs-keyword">for</span> i := <span class="hljs-number">1</span>; i &lt;= <span class="hljs-number">10</span>; i++ {
        allowed := limiter.Allow()
        fmt.Printf(<span class="hljs-string">"Request %d: Allowed = %t\n"</span>, i, allowed)
        time.Sleep(<span class="hljs-number">2</span> * time.Second)
    }
}</code></pre></div>
<h3 id="参考资料">参考资料</h3>
<ul>
<li><a title="https://cloud.google.com/apis/docs/rate-limiting" href="https://cloud.google.com/apis/docs/rate-limiting">Rate limiting, API keys, and quotas (Google Cloud)</a></li>
<li><a title="https://www.toptal.com/nodejs/introduction-rate-limiting-nodejs" href="https://www.toptal.com/nodejs/introduction-rate-limiting-nodejs">Understanding and Implementing Rate Limiting in Node.js (Toptal)</a></li>
<li><a title="https://gist.github.com/peteti/6b89b1c6e91e6f9759b9a1a0e3a3df24" href="https://gist.github.com/peteti/6b89b1c6e91e6f9759b9a1a0e3a3df24">Sliding Window Rate Limiter in Golang (GitHub Gist)</a></li>
<li><a title="https://www.tomhudson.dev/blog/2020/07/building-a-rate-limiter-in-go" href="https://www.tomhudson.dev/blog/2020/07/building-a-rate-limiter-in-go">Building a rate limiter in Go (Tom Hudson's Blog)</a></li>
<li><a title="https://golangcode.com/rate-limiting-using-go/" href="https://golangcode.com/rate-limiting-using-go/">Rate limiting using the token bucket algorithm (Golang Code)</a></li>
<li><a title="https://redislabs.com/redis-best-practices/basic-rate-limiting/" href="https://redislabs.com/redis-best-practices/basic-rate-limiting/">Redis-based rate limiting (Redis Labs)</a></li>
<li><a title="https://www.nginx.com/blog/rate-limiting-nginx/" href="https://www.nginx.com/blog/rate-limiting-nginx/">Rate limiting with Nginx (Nginx)</a></li>
</ul>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[嵌入式时间序列数据库的具体时间]]></title>
            <guid>d13a4eb729314e1bb452bd2842e9f785</guid>
            <pubDate>Tue, 11 Apr 2023 13:54:46 GMT</pubDate>
            <content:encoded><![CDATA[<p>Here's an example of a simple embedded time series database using BoltDB as the storage engine in a Golang program:</p>
<ol>
<li>First, install the BoltDB package:</li>
</ol>
<div><pre class="hljs"><code>go get github.com/boltdb/bolt</code></pre></div>
<ol start="2">
<li>Create a new file, timeseries.go, and import the required packages:</li>
</ol>
<div><pre class="hljs"><code><span class="hljs-keyword">package</span> main

<span class="hljs-keyword">import</span> (
    <span class="hljs-string">"bytes"</span>
    <span class="hljs-string">"encoding/binary"</span>
    <span class="hljs-string">"encoding/gob"</span>
    <span class="hljs-string">"log"</span>
    <span class="hljs-string">"time"</span>

    <span class="hljs-string">"github.com/boltdb/bolt"</span>
)</code></pre></div>
<ol start="3">
<li>Define the data structures for the time series data point:</li>
</ol>
<div><pre class="hljs"><code><span class="hljs-keyword">type</span> DataPoint <span class="hljs-keyword">struct</span> {
    Timestamp time.Time
    Value     <span class="hljs-keyword">float64</span>
}</code></pre></div>
<ol start="4">
<li>Initialize the BoltDB database:</li>
</ol>
<div><pre class="hljs"><code><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">initDB</span><span class="hljs-params">()</span> *<span class="hljs-title">bolt</span>.<span class="hljs-title">DB</span></span> {
    db, err := bolt.Open(<span class="hljs-string">"timeseries.db"</span>, <span class="hljs-number">0600</span>, <span class="hljs-literal">nil</span>)
    <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> {
        log.Fatal(err)
    }
    <span class="hljs-keyword">return</span> db
}</code></pre></div>
<ol start="5">
<li>Create a bucket for storing time series data:</li>
</ol>
<div><pre class="hljs"><code><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">createBucket</span><span class="hljs-params">(db *bolt.DB, bucketName <span class="hljs-keyword">string</span>)</span></span> {
    err := db.Update(<span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(tx *bolt.Tx)</span> <span class="hljs-title">error</span></span> {
        _, err := tx.CreateBucketIfNotExists([]<span class="hljs-keyword">byte</span>(bucketName))
        <span class="hljs-keyword">return</span> err
    })

    <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> {
        log.Fatal(err)
    }
}</code></pre></div>
<ol start="6">
<li>Implement the <code>writeDataPoint</code> function:</li>
</ol>
<div><pre class="hljs"><code><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">writeDataPoint</span><span class="hljs-params">(db *bolt.DB, bucketName <span class="hljs-keyword">string</span>, dataPoint DataPoint)</span></span> {
    err := db.Update(<span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(tx *bolt.Tx)</span> <span class="hljs-title">error</span></span> {
        b := tx.Bucket([]<span class="hljs-keyword">byte</span>(bucketName))

        <span class="hljs-comment">// Serialize the DataPoint</span>
        buf := bytes.NewBuffer(<span class="hljs-literal">nil</span>)
        err := gob.NewEncoder(buf).Encode(dataPoint)
        <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> {
            <span class="hljs-keyword">return</span> err
        }

        <span class="hljs-comment">// Write the serialized DataPoint to the bucket</span>
        key := <span class="hljs-built_in">make</span>([]<span class="hljs-keyword">byte</span>, <span class="hljs-number">8</span>)
        binary.BigEndian.PutUint64(key, <span class="hljs-keyword">uint64</span>(dataPoint.Timestamp.UnixNano()))
        <span class="hljs-keyword">return</span> b.Put(key, buf.Bytes())
    })

    <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> {
        log.Fatal(err)
    }
}</code></pre></div>
<ol start="7">
<li>Implement the <code>readDataPoints</code> function:</li>
</ol>
<div><pre class="hljs"><code><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">readDataPoints</span><span class="hljs-params">(db *bolt.DB, bucketName <span class="hljs-keyword">string</span>)</span> []<span class="hljs-title">DataPoint</span></span> {
    <span class="hljs-keyword">var</span> dataPoints []DataPoint

    err := db.View(<span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(tx *bolt.Tx)</span> <span class="hljs-title">error</span></span> {
        b := tx.Bucket([]<span class="hljs-keyword">byte</span>(bucketName))

        c := b.Cursor()
        <span class="hljs-keyword">for</span> k, v := c.First(); k != <span class="hljs-literal">nil</span>; k, v = c.Next() {
            <span class="hljs-keyword">var</span> dataPoint DataPoint
            err := gob.NewDecoder(bytes.NewReader(v)).Decode(&amp;dataPoint)
            <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> {
                <span class="hljs-keyword">return</span> err
            }
            dataPoints = <span class="hljs-built_in">append</span>(dataPoints, dataPoint)
        }
        <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>
    })

    <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> {
        log.Fatal(err)
    }

    <span class="hljs-keyword">return</span> dataPoints
}</code></pre></div>
<ol start="8">
<li>Use the database in the <code>main</code> function:</li>
</ol>
<div><pre class="hljs"><code><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> {
    db := initDB()
    <span class="hljs-keyword">defer</span> db.Close()

    bucketName := <span class="hljs-string">"timeseries"</span>

    createBucket(db, bucketName)

    dataPoint := DataPoint{
        Timestamp: time.Now(),
        Value:     <span class="hljs-number">42.0</span>,
    }
    writeDataPoint(db, bucketName, dataPoint)

    dataPoints := readDataPoints(db, bucketName)
    log.Println(dataPoints)
}</code></pre></div>
<p>This example demonstrates a very basic embedded time series database in Golang using BoltDB. You can extend this code to implement more advanced features like data partitioning, indexing, querying capabilities, and data management strategies as needed.</p>
<h2 id="索引的设计">索引的设计</h2>
<p>为时间序列数据库设计索引有助于提高数据检索效率和查询性能。在提供的使用BoltDB的示例中，您可以使用时间戳本身作为键，这已经提供了一种简单的索引形式。然而，如果你需要更高级的索引策略，你可以考虑以下方法:</p>
<ol>
<li>Time-based partitioning:<br />
根据时间戳将时间序列数据划分为更小的分区或bucket。每个分区可以表示一个固定的时间范围，例如一个小时、一天或一周。将每个分区单独存储在一个BoltDB桶中，可以提高数据的组织性和查询性能。</li>
</ol>
<div><pre class="hljs"><code><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">partitionKey</span><span class="hljs-params">(timestamp time.Time)</span> <span class="hljs-title">string</span></span> {
    <span class="hljs-comment">// Example: create partitions by day</span>
    <span class="hljs-keyword">return</span> timestamp.Format(<span class="hljs-string">"2006-01-02"</span>)
}</code></pre></div>
<ol start="2">
<li>Secondary indexing:<br />
如果时间序列数据具有附加属性，例如标记或标签，则可以创建辅助索引以加快基于这些属性的查询速度。要实现二级索引，您可以创建额外的BoltDB桶来存储对主数据点的引用。</li>
</ol>
<div><pre class="hljs"><code><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">writeSecondaryIndex</span><span class="hljs-params">(db *bolt.DB, indexBucketName <span class="hljs-keyword">string</span>, dataPointKey []<span class="hljs-keyword">byte</span>, indexValue <span class="hljs-keyword">string</span>)</span></span> {
    err := db.Update(<span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(tx *bolt.Tx)</span> <span class="hljs-title">error</span></span> {
        b := tx.Bucket([]<span class="hljs-keyword">byte</span>(indexBucketName))

        <span class="hljs-comment">// Store the data point key with the index value</span>
        <span class="hljs-keyword">return</span> b.Put([]<span class="hljs-keyword">byte</span>(indexValue), dataPointKey)
    })

    <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> {
        log.Fatal(err)
    }
}</code></pre></div>
<ol start="3">
<li>Time-based indexing:<br />
创建一个额外的索引，以加快需要特定时间范围或聚合的查询。例如，您可以创建一个索引来存储每个分区的最小值、最大值或平均值。这有助于加快需要在给定时间范围内计算汇总统计信息的查询。</li>
</ol>
<div><pre class="hljs"><code><span class="hljs-keyword">type</span> TimeRangeSummary <span class="hljs-keyword">struct</span> {
    Min <span class="hljs-keyword">float64</span>
    Max <span class="hljs-keyword">float64</span>
    Avg <span class="hljs-keyword">float64</span>
}

<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">writeTimeRangeIndex</span><span class="hljs-params">(db *bolt.DB, indexBucketName <span class="hljs-keyword">string</span>, partitionKey <span class="hljs-keyword">string</span>, summary TimeRangeSummary)</span></span> {
    err := db.Update(<span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(tx *bolt.Tx)</span> <span class="hljs-title">error</span></span> {
        b := tx.Bucket([]<span class="hljs-keyword">byte</span>(indexBucketName))

        <span class="hljs-comment">// Serialize the summary</span>
        buf := bytes.NewBuffer(<span class="hljs-literal">nil</span>)
        err := gob.NewEncoder(buf).Encode(summary)
        <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> {
            <span class="hljs-keyword">return</span> err
        }

        <span class="hljs-comment">// Write the serialized summary to the index bucket</span>
        <span class="hljs-keyword">return</span> b.Put([]<span class="hljs-keyword">byte</span>(partitionKey), buf.Bytes())
    })

    <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> {
        log.Fatal(err)
    }
}</code></pre></div>
<ol start="4">
<li>Updating and maintaining indexes:<br />
在添加新数据点或修改现有数据点时，请确保相应更新相应的索引。这可能需要更新二级索引或基于时间的索引结构，例如时间范围摘要统计信息。</li>
</ol>
<p>记住，建立索引是有代价的。虽然它可以显著提高查询性能，但也会增加数据库设计的复杂性，并增加写入操作的开销。必须分析应用程序的查询模式和需求，以确定最合适的索引策略。</p>
<h2 id="基于文件的删除策略">基于文件的删除策略</h2>
<p>To execute a delete strategy based on the database file size, you can monitor the file size periodically and trigger the deletion process once it exceeds a specified threshold. Here's how you can implement this strategy in your Golang program:</p>
<ol>
<li>Add a new global variable for the maximum allowed file size in bytes at the top of your <code>timeseries.go</code> file:</li>
</ol>
<div><pre class="hljs"><code><span class="hljs-keyword">const</span> maxFileSize <span class="hljs-keyword">int64</span> = <span class="hljs-number">1000000000</span> <span class="hljs-comment">// 1 GB</span></code></pre></div>
<ol start="2">
<li>Create a function to check the current database file size:</li>
</ol>
<div><pre class="hljs"><code><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">getFileSize</span><span class="hljs-params">(filepath <span class="hljs-keyword">string</span>)</span> <span class="hljs-params">(<span class="hljs-keyword">int64</span>, error)</span></span> {
    fileInfo, err := os.Stat(filepath)
    <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> {
        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>, err
    }
    <span class="hljs-keyword">return</span> fileInfo.Size(), <span class="hljs-literal">nil</span>
}</code></pre></div>
<ol start="3">
<li>Implement a function to delete a certain percentage of the oldest data points when the file size exceeds the threshold. The percentage is defined by the deletePercentage parameter:</li>
</ol>
<div><pre class="hljs"><code><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">deleteDataPointsByPercentage</span><span class="hljs-params">(db *bolt.DB, bucketName <span class="hljs-keyword">string</span>, deletePercentage <span class="hljs-keyword">float64</span>)</span></span> {
    <span class="hljs-keyword">if</span> deletePercentage &lt; <span class="hljs-number">0</span> || deletePercentage &gt; <span class="hljs-number">1</span> {
        log.Println(<span class="hljs-string">"Invalid delete percentage. It must be between 0 and 1."</span>)
        <span class="hljs-keyword">return</span>
    }

    err := db.Update(<span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(tx *bolt.Tx)</span> <span class="hljs-title">error</span></span> {
        b := tx.Bucket([]<span class="hljs-keyword">byte</span>(bucketName))
        c := b.Cursor()

        totalDataPoints := <span class="hljs-number">0</span>
        <span class="hljs-keyword">for</span> k, _ := c.First(); k != <span class="hljs-literal">nil</span>; k, _ = c.Next() {
            totalDataPoints++
        }

        deleteCount := <span class="hljs-keyword">int</span>(<span class="hljs-keyword">float64</span>(totalDataPoints) * deletePercentage)

        <span class="hljs-keyword">for</span> i := <span class="hljs-number">0</span>; i &lt; deleteCount; i++ {
            k, _ := c.First()
            <span class="hljs-keyword">if</span> k != <span class="hljs-literal">nil</span> {
                <span class="hljs-keyword">if</span> err := c.Delete(); err != <span class="hljs-literal">nil</span> {
                    <span class="hljs-keyword">return</span> err
                }
            }
        }
        <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>
    })

    <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> {
        log.Fatal(err)
    }
}</code></pre></div>
<ol start="4">
<li>Monitor the file size periodically in your <code>main</code> function and trigger the deletion when it exceeds the threshold. Use a ticker to check the file size at a specific interval, such as once per hour:</li>
</ol>
<div><pre class="hljs"><code><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> {
    db := initDB()
    <span class="hljs-keyword">defer</span> db.Close()

    bucketName := <span class="hljs-string">"timeseries"</span>

    createBucket(db, bucketName)

    <span class="hljs-comment">// Start the ticker for checking file size and triggering deletion</span>
    fileSizeTicker := time.NewTicker(<span class="hljs-number">1</span> * time.Hour)
    <span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> {
        <span class="hljs-keyword">for</span> <span class="hljs-keyword">range</span> fileSizeTicker.C {
            fileSize, err := getFileSize(<span class="hljs-string">"timeseries.db"</span>)
            <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> {
                log.Println(<span class="hljs-string">"Error checking file size:"</span>, err)
                <span class="hljs-keyword">continue</span>
            }

            <span class="hljs-keyword">if</span> fileSize &gt;= maxFileSize {
                log.Println(<span class="hljs-string">"Database file size exceeded threshold. Deleting oldest data points."</span>)
                deleteDataPointsByPercentage(db, bucketName, <span class="hljs-number">0.1</span>) <span class="hljs-comment">// Deletes 10% of the oldest data points</span>
            }
        }
    }()

    <span class="hljs-comment">// ... (the rest of your main function)</span>
}</code></pre></div>
<p>This implementation checks the database file size periodically and deletes a specified percentage of the oldest data points when the file size exceeds the threshold. Adjust the maxFileSize and deletePercentage variables according to your requirements. To minimize the deletion frequency, increase the file size threshold or decrease the percentage of data points to delete.</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[如何设计嵌入式时间序列数据库]]></title>
            <guid>e51232f5bfe94e348d8ed41115243834</guid>
            <pubDate>Tue, 11 Apr 2023 13:48:29 GMT</pubDate>
            <content:encoded><![CDATA[<p>在Golang程序中设计嵌入式时间序列数据库涉及一系列步骤，从选择合适的存储引擎到实现数据管理策略。下面是一个高级指南，帮助您在Golang中设计和实现嵌入式时间序列数据库:</p>
<ul>
<li>
<p>选择存储引擎: 对于嵌入式时间序列数据库，可以考虑使用嵌入式键值存储引擎，如BoltDB、Badger或LevelDB。这些引擎轻量级、快速且易于集成到Golang应用程序中。</p>
</li>
<li>
<p>定义数据模型: 设计一个有效地表示时间序列数据的数据模型。使用<code>structs</code>或<code>protobuf</code>这样的结构来定义数据模式。考虑使用时间戳作为键，使用序列化的数据点作为值，以实现高效的存储和检索。</p>
</li>
<li>
<p>设置存储引擎:</p>
<ul>
<li>将选择的存储引擎库导入到Golang程序中。</li>
<li>配置和初始化存储引擎，创建数据库实例。</li>
<li>实现打开、关闭和管理数据库连接的方法。</li>
</ul>
</li>
<li>
<p>实现数据存储和检索:</p>
<ul>
<li>创建从存储引擎写入和读取数据点的方法。</li>
<li>使用编码技术(如协议缓冲区、JSON或MessagePack)序列化和反序列化数据点。</li>
<li>使用批写和压缩优化存储和写性能。</li>
</ul>
</li>
<li>
<p>设计索引和分区:</p>
<ul>
<li>通过根据数据点的时间戳将数据点分组到桶中，实现基于时间的分区。</li>
<li>创建索引以实现高效的数据检索和查询。</li>
<li>利用存储引擎的内置索引功能或实现自定义索引解决方案。</li>
</ul>
</li>
<li>
<p>实现查询功能:</p>
<ul>
<li>设计一个简单的查询API或语言来与时间序列数据交互。</li>
<li>实现过滤、聚合和基于时间的操作的查询功能。</li>
<li>使用缓存、物化视图或预计算聚合优化查询性能。</li>
</ul>
</li>
<li>
<p>数据管理策略:</p>
<ul>
<li>实现数据保留策略，自动删除旧数据点或downsample数据，节省存储空间。</li>
<li>使用数据压缩技术可以减小存储空间大小并提高性能。</li>
</ul>
</li>
<li>
<p>测试和基准测试:</p>
<ul>
<li>为所有主要功能编写测试，以确保嵌入式时间序列数据库的正确性和可靠性。</li>
<li>对时间序列数据库的性能进行基准测试，以确定潜在的瓶颈和需要改进的领域。</li>
</ul>
</li>
</ul>
<p>通过执行这些步骤，您可以在Golang程序中设计和实现高效的嵌入式时间序列数据库。确保持续监控、优化和维护数据库，以确保其可靠性和性能</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[如何大规模配置裸机电信云平台]]></title>
            <guid>df4af15487b943e5938ac6f9cfc97490</guid>
            <pubDate>Wed, 01 Feb 2023 16:39:35 GMT</pubDate>
            <content:encoded><![CDATA[<blockquote>
<p>使用通过 OpenShift 实施的 Kubernetes 大规模通过和配置裸机集群。</p>
</blockquote>
<p>自动化系统供应对于 IT 或网络系统管理员来说至关重要。许多技术和标准试图解决这个问题；有些是供应商中立的，有些是特定于供应商的。后者在无线网络中尤其如此，其中每个网络设备提供商都需要其关联的元素/网络管理系统来控制其网络元素。</p>
<p>鉴于无线电接入网络 (RAN) 分解和解聚的兴起，Open RAN 等标准机构专注于定义 RAN 组件无线电单元 (RU)、分布式单元 (DU) 和中央单元 (CU) 之间的可互操作接口。与此同时，在 O-RAN 联盟的领导下，行业推动 RAN 组件虚拟化和云化，因此它们的生命周期可以独立于运行它们的平台进行管理。这种由商用现成 (COTS) 服务器组成的平台需要高度配置才能发挥 5G 的优势。</p>
<p><img src="/_resources/480c1db4ac474a9fad80ca3db516e577.png" /></p>
<center style="font-size:14px;color:#C0C0C0;text-decoration:underline" class="jop-noMdConv">Alexis de Talhouët &amp; Federico Rossi, CC BY-SA 4.0</center>
<p>这带来的挑战之一是大规模供应和配置该平台的能力；一个电信服务提供商可能有数千个 RAN 部署。该平台包括服务器和管理程序或容器编排系统。</p>
<p>本文将使用OpenShift实现的容器编排系统Kubernetes；特别是 Red Hat OpenShift 4.11。</p>
<h2 id="解决方案概述">解决方案概述</h2>
<p>与 Red Hat 和合作伙伴一起部署云原生 5G 开放式 RAN 提出了要求和高级方法。它包含三个主要元素：</p>
<ul>
<li>用于大规模部署的云原生平台</li>
<li>GitOps 的自动化和操作</li>
<li>蓬勃发展的合作伙伴生态系统</li>
</ul>
<p>该解决方案旨在通过利用 Red Hat OpenShift 提供的一组广为采用的通用 API（无论是在中央、区域还是边缘区域）在整个环境中提供相同的管理、操作和用户体验。该水平平台不一定是一个实例，而是一组共同管理的实例。</p>
<p>这些 RAN 部署模型使用一个管理环境来控制其他模型，将它们视为牛而不是宠物。它被称为管理集群或中心集群。远程环境称为托管集群。</p>
<p>下图描述了由 Red Hat Advanced Cluster Management (RHACM) 启用的中央实体如何配置和操作由以下任何一项组成的远程环境：</p>
<ul>
<li>一个完整的 OpenShift 集群（三个控制平面和至少两个计算节点）</li>
<li>一个紧凑的 OpenShift 集群（三个节点同时充当控制和计算）</li>
<li>由一个节点组成的单节点OpenShift</li>
<li>远程工作节点（远程连接到控制平面，托管在管理集群中，或远程）</li>
</ul>
<p><img src="/_resources/95b6c8a6deb2409da084e89c743082a2.png" /></p>
<p>最后，要定义一次，随处部署，并持续协调运行状态与真实来源，请遵循 GitOps 方法，例如 Red Hat OpenShift GitOps。</p>
<p>大规模采用 GitOps 存在不同的实施模型，但这些不是本文的主题。</p>
<p><img src="/_resources/84aa23769b3640ce89928c8fb45f5958.png" /></p>
<h2 id="远程裸机集群生命周期管理">远程裸机集群生命周期管理</h2>
<p>OpenStack 社区首先通过 Ironic 项目解决了这一需求。目标是通过通用（预引导执行环境 [PXE] 和智能平台管理接口 [IPMI]）和特定于供应商的远程管理协议（底板管理控制器 [BMC]）来管理硬件。该项目成为 <a title="https://metal3.io/" href="https://metal3.io/">Metal3</a> 的垫脚石，为 Kubernetes 启用了此类功能。</p>
<p>使用<a title="https://console.redhat.com/openshift/assisted-installer/clusters" href="https://console.redhat.com/openshift/assisted-installer/clusters">红帽 SaaS 辅助安装程序平台</a>在红帽混合云控制台上部署第一个集群非常简单，即使您使用自己的映像注册表也是如此。阅读<a title="https://cloud.redhat.com/blog/making-openshift-on-bare-metal-easy" href="https://cloud.redhat.com/blog/making-openshift-on-bare-metal-easy">使裸机上的 OpenShift 变得简单</a>，以全面了解该过程。</p>
<p>主要要求是出站互联网访问；不需要入站连接。辅助安装程序是一项服务：</p>
<ul>
<li>允许基础架构管理员生成发现图像</li>
<li>发现基础架构管理员使用发现映像启动的主机</li>
<li>允许集群创建者从可用主机定义集群</li>
<li>在开始之前验证安装</li>
<li>监控装置</li>
<li>收集日志</li>
<li>发布指标供内部使用</li>
<li>允许集群创建者将主机添加到现有集群</li>
</ul>
<p>创建第一个集群后，您必须安装 RHACM 和 Red Hat OpenShift GitOps。接下来，您可以按照 GitOps 方法论来创建和配置后续集群。</p>
<p><a title="https://cloud.redhat.com/blog/zero-touch-provisioning-for-factory-workflows" href="https://cloud.redhat.com/blog/zero-touch-provisioning-for-factory-workflows">工厂工作流程的零接触配置</a>是了解启用裸机服务器远程配置以实现全自动集群安装的策略的好方法。它在引擎盖下使用 Metal3 并严重依赖 BMC 和配置接口 MAC 地址。</p>
<p>在高层次上，您将使用工厂集群部署一个独立的集群，如下所示：</p>
<ol>
<li>安装工厂集群：创建工厂集群（管理）创建OpenShift集群。</li>
<li>创建边缘集群：使用工厂集群在 OEM 硬件上创建完全可操作的 OpenShift 集群（辐射）。</li>
<li>配置边缘集群：在最终客户站点（边缘）解压并配置 OpenShift 集群。</li>
</ol>
<p>此外，RHACM 还提供站点规划和策略模板，支持大规模部署和配置集群。</p>
<p>在<a title="https://docs.openshift.com/container-platform/4.11/scalability_and_performance/ztp-deploying-disconnected.html" href="https://docs.openshift.com/container-platform/4.11/scalability_and_performance/ztp-deploying-disconnected.html">文档</a>中查找更多详细信息。</p>
<p><img src="/_resources/8c611371be344eb88c49de5a88b8fa5d.png" /></p>
<p>##. 拓扑感知生命周期管理</p>
<p>需要一个强大的基础设施生命周期管理工具来满足在整个生命周期内大规模管理基础设施的技术和业务需求。</p>
<p>它应该考虑以下几点：</p>
<ol>
<li>定义最低可用性要求的服务级别协议 (SLA)</li>
<li>需要逐步向队列推出的操作程序（例如，作为初始冒烟测试升级的金丝雀集群）</li>
<li>大规模自动化要求</li>
</ol>
<p>拓扑感知生命周期操作员 （TALO） 在操作环境中大规模管理这些事件。</p>
<p><a title="https://www.redhat.com/en/engage/discover-automating-edge-20220510?intcmp=7013a0000025wJwAAI" href="https://www.redhat.com/en/engage/discover-automating-edge-20220510?intcmp=7013a0000025wJwAAI">Automating the last mile: Ensuring consistency and scalability at the edge</a></p>
<p>一个示例用例是具有 RAN 覆盖范围的大型集群 （DU） 队列。更新分波次应用，以确保保持足够的 RAN 覆盖范围。SLA 指定覆盖区域内维护事件期间不可用群集的最大数量。</p>
<p><img src="/_resources/c3702dd1798242aebddf8376878c10df.png" /></p>
<ul>
<li>绿色和蓝色集群（集群组升级 [CGU] 1 和 CGU 2）配对以提供服务覆盖范围重叠。</li>
<li>操作程序规定可以更新三个集群（最多）。</li>
<li>CGU 1 以 3 个为批次更新绿色簇。</li>
<li>CGU 2 与 CGU 1 链接，并在 CGU 1 完成时以三个为一组更新蓝色集群。</li>
</ul>
<p>TALO 通过提供集成的备份和恢复（回滚）功能，将维护窗口期间的风险降至最低。此功能可创建升级前备份，并提供在升级失败时快速恢复单节点 OpenShift （SNO） 的过程。如果升级失败，此功能允许将 SNO 恢复到以前版本的 OpenShift 的工作状态，而无需重新配置应用程序。</p>
<p>群集升级需要在维护时段内完成。该窗口还需要包括解决失败升级的时间。必须将 OpenShift 版本工件下载到集群才能进行升级。某些群集托管注册表的中心群集的带宽可能有限，因此很难在所需时间内完成升级。在升级之前，群集上必须存在所需的项目，以确保升级适合维护时段。</p>
<p>为了实现这些操作过程，TALO 以声明性方式管理一个或多个 OpenShift 集群的 RHACM 策略部署。</p>
<h2 id="云原生平台配置">云原生平台配置</h2>
<p>该方法可以大规模部署和管理群集。查看每个群集的较低级别组件以启用性能调整。这些是构成上述政策的要素。</p>
<p>目标是使用 Kubernetes 资源模型完成 100% 的硬件配置，支持将预期配置声明为代码，并通过 GitOps 促进操作管理。</p>
<p>下图显示了节点操作系统和所有支持的运算符，启用了特定的节点配置。</p>
<p><img src="/_resources/fa48f03b23a94197ac92586764c46514.png" /></p>
<p>以下是5G核心网应用最重要的运营商：</p>
<ul>
<li><a title="https://docs.openshift.com/container-platform/4.11/nodes/nodes/nodes-node-tuning-operator.html" href="https://docs.openshift.com/container-platform/4.11/nodes/nodes/nodes-node-tuning-operator.html">Node Tuning Operator</a>可用于优化基础操作系统以减少延迟。它使用性能配置文件，并负责：
<ul>
<li>HugePages</li>
<li>Topology manager policy (NUMA)</li>
<li>CPU reservation and isolation</li>
<li>Power consumption scheme</li>
<li>Real-time kernel</li>
<li>Network interface controller (NIC) queues tuning (DPDK)</li>
<li>IRQ dynamic load-balancing</li>
</ul>
</li>
<li><a title="https://docs.openshift.com/container-platform/4.11/hardware_enablement/psap-special-resource-operator.html" href="https://docs.openshift.com/container-platform/4.11/hardware_enablement/psap-special-resource-operator.html">Special Resource Operator</a> 允许您加载特定的内核模块和设备驱动程序。此组件仍处于技术预览阶段，这意味着不应在生产中使用它。如果要使用它，建议获取指导。</li>
<li><a title="https://docs.openshift.com/container-platform/4.11/networking/k8s_nmstate/k8s-nmstate-about-the-k8s-nmstate-operator.html" href="https://docs.openshift.com/container-platform/4.11/networking/k8s_nmstate/k8s-nmstate-about-the-k8s-nmstate-operator.html">NMState Operator</a> 启用接口配置，无论其类型如何。它通常用于定义绑定接口以及 VLAN 子接口。</li>
<li><a title="https://docs.openshift.com/container-platform/4.11/networking/hardware_networks/about-sriov.html" href="https://docs.openshift.com/container-platform/4.11/networking/hardware_networks/about-sriov.html">SR-IOV Operator</a>允许通过 SriovNetworkNodePolicy 配置 SR-IOV 支持的网卡，该策略配置：
<ul>
<li>MTU</li>
<li>Number of VFs</li>
<li>NIC selector</li>
<li>Device type (whether vfio-pci or netdev)<br />
需要 SriovNetwork 才能使用创建的设备。这将产生一个 NetworkAttachmentDefinition，然后 Pod 可以通过注释使用该定义。</li>
</ul>
</li>
</ul>
<p>5G RAN 或其他类型的工作负载还有其他几个运营商，例如Precision Time Protocol Operator, Intel Device Plugin Operator, FEC Operator, NVIDIA GPU Operator, and Network Operator.。每个都旨在抽象特定于硬件的功能，并使用 Kubernetes 资源模型启用其配置。</p>
<p>注意：许多operator支持告警、监控、服务保障、远程管理、证书管理等。</p>
<p>按应用程序和基础架构类型定义性能配置文件是释放性能的关键。</p>
<p>下图是 DU 性能配置文件所需的运算符示例。</p>
<p><img src="/_resources/cb79ca5609c94a50b6850813dca7dd0b.png" /></p>
<h2 id="展望未来">展望未来</h2>
<p>大规模预置和配置裸机集群的能力现已成为现实。但其他挑战依然存在，包括：</p>
<ul>
<li>使用统一的管理平台观察所有这些环境进行操作</li>
<li>实现自主系统（平台和网络），促进服务水平保证的可持续性</li>
<li>用于无缝应用通信的多集群网络（跨中央和边缘集群的分布式 SBA 5G 核心网）</li>
<li>增强调度能力，实现可持续计算</li>
</ul>
<p>请继续关注更多信息。同时，请随时查看我们在 <a title="https://www.redhat.com/en/events/red-hat-kubecon-cloudnativecon-na-2022" href="https://www.redhat.com/en/events/red-hat-kubecon-cloudnativecon-na-2022">KubeCon NA 2022</a> 上完成和展示的一些进展。</p>
<p><a title="https://www.redhat.com/architect/cloud-provisioning-scale" href="https://www.redhat.com/architect/cloud-provisioning-scale">原文连接</a></p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[6. 文档系统 ---- 关于结构]]></title>
            <guid>02ed0149cb0a4c5b865364a20e2fd29d</guid>
            <pubDate>Tue, 31 Jan 2023 16:31:31 GMT</pubDate>
            <content:encoded><![CDATA[<h2 id="为什么这不明显">为什么这不明显？</h2>
<p>这种结构很清晰，也很有效，但它不那么明显是有原因的，那就是文档的每个象限的特征与方案中相邻象限的特征重叠的方式。</p>
<p><img src="/_resources/c0b13b70118040068123301e5f90ba40.png" /></p>
<p>每个象限都与其相邻的两个象限相似：</p>
<ul>
<li>教程和操作指南都与描述实际步骤有关</li>
<li>操作指南和技术参考都是我们在工作、编码时所需要的</li>
<li>参考指南和解释都涉及理论知识</li>
<li>教程和解释在我们学习时最有用，而不是实际工作</li>
</ul>
<h2 id="崩溃的趋势">崩溃的趋势</h2>
<p>鉴于这些重叠，不同类型的文档相互混淆和混合也就不足为奇了。事实上，这些不同类型的文档相互之间有一种自然的引力，而且很难抗拒。它的作用是破坏结构，这就是为什么这么多文档看起来像这样：</p>
<p><img src="/_resources/4beabf32276340ae978dd4ea8e7f4daf.png" /></p>
<h2 id="系统的采用">系统的采用</h2>
<p>虽然很少能找到充分使用它的清晰示例，但大量文档以不同的方式识别这四个功能中的每一个。</p>
<p>该计划在重大项目中的良好示例包括：</p>
<ul>
<li><a title="https://docs.divio.com/" href="https://docs.divio.com/">Divio Developer Handbook</a></li>
<li><a title="https://docs.djangoproject.com/en/3.0/#how-the-documentation-is-organized" href="https://docs.djangoproject.com/en/3.0/#how-the-documentation-is-organized">Django’s documentation</a></li>
<li><a title="http://docs.django-cms.org/" href="http://docs.django-cms.org/">django CMS’s documentation</a></li>
</ul>
<p>即使在非常少的文档中也可以使用该系统，例如 <a title="https://docs.coreport.ch/" href="https://docs.coreport.ch/">CoReport（一个开源 COVID-19 报告项目）</a>。在这里，应用该系统为未来的文档创建了一个框架，有助于确保新材料符合要求。</p>
<p>有时文档非常少，以至于并非所有象限都准备好呈现，例如 <a title="https://github.com/flavours/getting-started-with-spring-boot/blob/master/README.md" href="https://github.com/flavours/getting-started-with-spring-boot/blob/master/README.md">Java 和 Spring-boot 入门</a>，它只包括教程、操作方法和参考资料。</p>
<p>尽管在每种情况下，无论多么微小甚至不完整，系统都受到尊重，各部分及其目的之间的明确区分将立即使作者和用户受益，并有助于指导材料在未来发展时的扩展。</p>
<h2 id="关于分析及其应用">关于分析及其应用</h2>
<p>本文中对文档的分析基于多年编写和维护文档的经验，并花费了大量时间考虑如何改进它。</p>
<p>它还基于来自各种学科的合理原则。例如，它的教程概念具有教学基础；它设定了一位导师和一位学习者，并将使用软件视为一门手艺，其中对一般原则的抽象理解来自于处理细节的具体步骤。</p>
<p>该系统定期在会谈和互动研讨会上展示。该分析已应用于众多项目，包括大型内部文档集，并在非常广泛的技术主题中多次获得可用性和可维护性的好处。</p>
<h2 id="参考">参考</h2>
<p><a title="https://documentation.divio.com/adoption/" href="https://documentation.divio.com/adoption/">https://documentation.divio.com/adoption/</a></p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[5. 文档系统 ---- 说明]]></title>
            <guid>d8e8b58f4e1f419cbbae1c5494b4a542</guid>
            <pubDate>Tue, 31 Jan 2023 16:28:41 GMT</pubDate>
            <content:encoded><![CDATA[<blockquote>
<p>解释或讨论，澄清和阐明特定主题。它们扩大了文档对某个主题的覆盖范围。</p>
</blockquote>
<p>他们以理解为导向。</p>
<p>解释同样可以描述为讨论；它们本质上是散漫的。它们是文档放松和从软件退后一步的机会，从更广阔的视野，从更高的层次甚至从不同的角度阐明它。您可能会想象一个讨论文档是在闲暇时阅读的，而不是阅读代码。</p>
<p>这部分文档很少明确创建，相反，解释片段散布在其他部分中。有时，该部分存在，但有一个名称，例如背景或其他注释或关键主题 - 这些名称并不总是有用的。</p>
<p>创建讨论并不像看起来那么容易 - 当您有某人问题的起点时，可以直接解释的事情在您有空白页并且必须写下一些相关内容时就不那么容易了。</p>
<p>主题不是由您想要完成的特定任务定义的，例如操作指南，或者您希望用户学习的内容，例如教程。它不是由一台机器定义的，比如参考资料。它是由您认为一次尝试涵盖的合理区域来定义的，因此讨论主题的划分有时可能有点武断。</p>
<h2 id="烹饪类比">烹饪类比</h2>
<p>想想一部在历史、科学和技术背景下讨论食物和烹饪的作品。这是关于烹饪和厨房的。</p>
<p>它不教授，它不是食谱的集合，它不只是描述。</p>
<p>相反，它从多个角度分析、考虑事物。它可能会解释为什么我们现在按照自己的方式做事，甚至可以描述糟糕的做事方式，或模糊的替代方案。</p>
<p>它加深了我们的知识并使它更丰富，即使它不是我们可以在任何实际意义上实际应用的知识——但它不需要是，为了有价值。</p>
<p>当我们想在更高层次上思考烹饪，并想更多地了解这个主题时，我们可能会在闲暇时阅读它，远离厨房本身。</p>
<h2 id="如何写出好的解释">如何写出好的解释</h2>
<h3 id="提供上下文">提供上下文</h3>
<p>解释是背景和上下文的地方——例如，Web 表单以及它们在 Django 中的处理方式，或在 Django CMS 中的搜索。</p>
<p>他们还可以解释为什么会这样——设计决策、历史原因、技术限制。</p>
<h3 id="讨论备选方案和意见">讨论备选方案和意见</h3>
<p>解释可以考虑替代方案，或针对同一问题的多种不同方法。例如，在一篇关于 Django 部署的文章中，考虑和评估不同的 Web 服务器选项是合适的，</p>
<p>讨论甚至可以考虑和权衡相反的意见——例如，测试模块是否应该在包目录中。</p>
<h3 id="不指导不提供技术参考">不指导，不提供技术参考</h3>
<p>解释应该做文档其他部分做不到的事情。这不是指导用户如何做某事的解释的地方。也不应提供技术说明。文档的这些功能已经在其他部分中得到了处理。</p>
<h2 id="divio-文档中的示例">Divio 文档中的示例</h2>
<p>看看我们的<a title="https://docs.divio.com/en/latest/reference/divio-cli" href="https://docs.divio.com/en/latest/reference/divio-cli">解释部分</a>（标题为“背景” - 只要目的明确，名称并不重要）。</p>
<p>这些文章没有教任何东西。他们不会告诉用户该做什么。它们不是参考指南。他们只是讨论特定的话题。用户不需要了解（例如）缓存或 CDN 或我们如何管理环境变量来使用平台或完成任何特定任务，但时间很可能会到来，届时某人的经验和平台使用将成为通过对这些事情有更清晰、更好、更深入的理解而得到改善。</p>
<p>这些文章提供了更大的图景和背景。用户是人；也许他们不需要严格地知道我们为什么以某种方式做某事，但知道这很可能会给他们带来一种满足感和舒适感，使他们成为更快乐的产品用户。</p>
<p><img src="/_resources/c72ddba88f2145d49101e1ecc623e823.png" /></p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[4. 文档系统 ---- 参考指南]]></title>
            <guid>d8969ada7b974ff5b02a21aa203533c6</guid>
            <pubDate>Tue, 31 Jan 2023 16:24:57 GMT</pubDate>
            <content:encoded><![CDATA[<blockquote>
<p>参考指南是对机器及其操作方法的技术说明。</p>
</blockquote>
<p>参考指南只有一项工作：描述。它们是由代码决定的，因为最终这就是它们描述的内容：关键类、函数、API，因此它们应该列出函数、字段、属性和方法等内容，并说明如何使用它们。</p>
<p>参考资料以信息为导向。</p>
<p>无论如何，技术参考可以包含示例来说明用法，但不应试图解释基本概念或如何实现常见任务。</p>
<p>参考资料应该简明扼要。</p>
<p>请注意，描述确实包括如何使用机器的基本描述 - 例如，如何实例化特定类或调用特定方法，或将某些内容传递给函数时必须采取的预防措施。然而，这只是其技术参考功能的一部分，强调不要与操作指南混淆 - 描述软件的正确使用（技术参考）与展示如何使用它来实现特定目的不同（操作文档）。</p>
<p>对于一些开发人员来说，参考指南是他们唯一能想到的文档。他们已经了解他们的软件，他们知道如何使用它。他们所能想到的其他人可能需要的只是有关它的技术信息。</p>
<p>参考资料往往写得很好。它甚至可以 - 在某种程度上 - 自动生成，但这本身是不够的。</p>
<h2 id="烹饪类比">烹饪类比</h2>
<p>考虑一篇关于某种成分的百科全书文章，比如生姜。</p>
<p>当您在参考书中查找生姜时，您需要的是有关该成分的信息——描述其来源、行为、化学成分以及烹饪方法的信息。</p>
<p>您希望无论查找什么成分，信息都会以类似的方式呈现。您希望了解基本事实，例如生姜是姜黄和豆蔻家族的一员。</p>
<p>这也是您希望收到有关潜在问题的警报的地方，例如：已知生姜会引起某些人的胃灼热或：生姜可能会干扰抗凝剂的作用，例如华法林或阿司匹林。</p>
<h2 id="如何写出好的参考指南">如何写出好的参考指南</h2>
<h3 id="围绕代码构建文档">围绕代码构建文档</h3>
<p>为参考文档提供与代码库相同的结构，以便用户可以同时浏览代码和文档。这也将帮助维护者查看参考文档丢失或需要更新的地方。</p>
<h3 id="始终如一">始终如一</h3>
<p>在参考指南中，结构、语气、格式都必须保持一致——就像百科全书或字典一样。</p>
<h3 id="除了描述什么都不做">除了描述什么都不做</h3>
<p>技术参考的唯一工作就是描述，尽可能清楚和完整。其他任何事情（解释、讨论、指导、推测、意见）不仅会分散注意力，而且会使它更难使用和维护。在适当的时候提供示例来说明描述。</p>
<p>避免使用参考资料来指导如何实现事物的诱惑，超出使用软件的基本范围，并且不允许对概念进行解释或对主题进行讨论。取而代之的是，链接到操作指南、解释和介绍性教程。</p>
<h3 id="准确">准确</h3>
<p>这些描述必须准确并保持最新。机器与您的描述之间的任何差异都将不可避免地导致用户误入歧途。</p>
<h3 id="divio-文档中的示例">Divio 文档中的示例</h3>
<p>查看我们的<a title="https://docs.divio.com/en/latest/reference/divio-cli" href="https://docs.divio.com/en/latest/reference/divio-cli">技术参考</a>部分中的示例。</p>
<p>这是一个典型的参考指南（在本例中，针对我们的 Divio CLI）。</p>
<p>本文所做的就是描述，以完整和准确的形式列出该工具的功能、命令和选项。</p>
<p>这不是一本友好或引人入胜的读物，但它的目的是尽可能快速和无干扰地查找有关功能的信息。</p>
<p><img src="/_resources/39dbb70411b14b989589918e6e9cc290.png" /></p>
]]></content:encoded>
        </item>
    </channel>
</rss>